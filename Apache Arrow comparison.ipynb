{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d61fe61",
   "metadata": {},
   "source": [
    "A Python notebook that demonstrates, documents and benchmarks the value of using Apache Arrow to read in a large (5Gb) CSV file of years of historic environmental monitoring sample data (available from https://pub.data.gov.bc.ca/datasets/949f2233-9612-4b06-92a9-903e817da659/ems_sample_results_historic_expanded.zip) and compute the mean Result from all measurements of the Parameter “Chromium Total” where the units were recorded in mg/L. \n",
    "\n",
    "- working solution reads file and computes correct mean,\n",
    "- provides indication of file sizes, read and compute times – with and without Arrow,\n",
    "- solution briefly explains Apache Arrow and documents value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdafcb9",
   "metadata": {},
   "source": [
    "## First, we get the time to read csv file and compute mean of Result without Apach Arrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37485fea",
   "metadata": {},
   "source": [
    "Get the time to read the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebbce1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file size is 5,322,234,734 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (30,33,42,43,44,45,47,49,52,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169.74040722846985, 210.940181016922]\n",
      "Reading CSV file 'ems_sample_results_historic_expanded.csv' took 190.34029412269592 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = '/Users/raysu/Downloads/ems_sample_results_historic_expanded.csv'\n",
    "\n",
    "# Display the size of the file\n",
    "file_size = os.path.getsize(csv_file)\n",
    "print(\"The CSV file size is {:,d} bytes\".format(file_size))\n",
    "\n",
    "# Run the test for a couple times and print the average time\n",
    "read_times = []\n",
    "for i in range(2):\n",
    "    file_read_start = time.time()\n",
    "    ems_df = pd.read_csv(csv_file)\n",
    "    file_read_end = time.time()\n",
    "    read_times.append(file_read_end - file_read_start)\n",
    "    \n",
    "file_read_time = sum(read_times)/len(read_times)\n",
    "print(read_times)\n",
    "print(\"Reading CSV file '{}' took {} seconds.\".format(os.path.basename(csv_file), file_read_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863543f6",
   "metadata": {},
   "source": [
    "Get the time to compute mean for all Chromium Total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da6c9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.400696039199829, 1.357544183731079, 1.2976970672607422]\n",
      "Computing the mean of 'Chromium Total' took 2.018645763397217 seonds, and the mean is 1.5669242911547947.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMS_ID</th>\n",
       "      <th>PARAMETER</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0190039</td>\n",
       "      <td>Chromium Total</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0131140</td>\n",
       "      <td>Chromium Total</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>E206114</td>\n",
       "      <td>Chromium Total</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0301315</td>\n",
       "      <td>Chromium Total</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0900503</td>\n",
       "      <td>Chromium Total</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMS_ID       PARAMETER  RESULT\n",
       "603   0190039  Chromium Total    0.02\n",
       "701   0131140  Chromium Total    0.01\n",
       "875   E206114  Chromium Total    0.02\n",
       "1100  0301315  Chromium Total    0.05\n",
       "1779  0900503  Chromium Total    0.01"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_times = []\n",
    "result_means = set()\n",
    "\n",
    "for i in range(3):\n",
    "    compute_start = time.time()\n",
    "    ct_df = ems_df[[\"EMS_ID\", 'PARAMETER', 'RESULT']]\n",
    "    chromium_total_df = ct_df.loc[ct_df['PARAMETER'] == 'Chromium Total']\n",
    "    result_means.add(chromium_total_df['RESULT'].mean())\n",
    "    compute_end = time.time()\n",
    "    compute_times.append(compute_end - compute_start)\n",
    "\n",
    "print(compute_times)\n",
    "mean_compute_time = sum(compute_times)/len(compute_times)\n",
    "if len(result_means) == 1:\n",
    "    ct_result_mean = list(result_means)[0]\n",
    "else:\n",
    "    print(\"Unexpected things happened when calculating the mean of the Result.\")\n",
    "\n",
    "print(\"Computing the mean of 'Chromium Total' took {} seconds, and the mean is {}.\".format(mean_compute_time, ct_result_mean))\n",
    "chromium_total_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57e1a6",
   "metadata": {},
   "source": [
    "## Now we try it with Apache Arrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e7dc6",
   "metadata": {},
   "source": [
    "**Please restart the Kernel before running the cells below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36dc8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file size is 5,322,234,734 bytes\n",
      "Start reading EMS sample result history with Apache Arrow...\n",
      "[88.05579113960266, 433.3258948326111]\n",
      "Reading CSV file 'ems_sample_results_historic_expanded.csv' took 260.6908429861069 seconds with Apache Arrow.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyarrow import csv\n",
    "\n",
    "csv_file = '/Users/raysu/Downloads/ems_sample_results_historic_expanded.csv'\n",
    "\n",
    "# Display the size of the file\n",
    "file_size = os.path.getsize(csv_file)\n",
    "print(\"The CSV file size is {:,d} bytes\".format(file_size))\n",
    "\n",
    "print(\"Start reading EMS sample result history with Apache Arrow...\")\n",
    "\n",
    "# Run the test for 3 times and print the average time\n",
    "read_times = []\n",
    "for i in range(2):\n",
    "    file_read_start = time.time()\n",
    "    ems_table = csv.read_csv(csv_file)\n",
    "    file_read_end = time.time()\n",
    "    read_times.append(file_read_end - file_read_start)\n",
    "    \n",
    "file_read_time = sum(read_times)/len(read_times)\n",
    "print(read_times)\n",
    "print(\"Reading CSV file '{}' took {} seconds with Apache Arrow.\".format(os.path.basename(csv_file), file_read_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ae8345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyArrow table conversion time is 1.1858611106872559 seconds.\n",
      "PyArrow table conversion time is 1.2266318798065186 seconds.\n",
      "PyArrow table conversion time is 1.2164068222045898 seconds.\n",
      "[2.1485610008239746, 2.1854379177093506, 2.1801540851593018]\n",
      "Computing the mean of 'Chromium Total' took 2.171384334564209 seonds, and the mean is 1.5669242911547947.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.compute as pc\n",
    "\n",
    "compute_times = []\n",
    "result_means = set()\n",
    "\n",
    "for i in range(3):\n",
    "    compute_start = convert_start = time.time()\n",
    "    ems_df = ems_table.select(['EMS_ID', 'PARAMETER', 'RESULT']).to_pandas()\n",
    "    convert_end = time.time()\n",
    "    ct_result_df = ems_df.loc[ems_df['PARAMETER'] == 'Chromium Total']\n",
    "    result_means.add(ct_result_df['RESULT'].mean())\n",
    "    compute_end = time.time()\n",
    "    compute_times.append(compute_end - compute_start)\n",
    "    print(\"PyArrow table conversion time is {} seconds.\".format(convert_end - convert_start))\n",
    "    \n",
    "print(compute_times)\n",
    "mean_compute_time = sum(compute_times)/len(compute_times)\n",
    "if len(result_means) == 1:\n",
    "    ct_result_mean = list(result_means)[0]\n",
    "else:\n",
    "    print(\"Unexpected things happened when calculating the mean of the Result.\")\n",
    "\n",
    "print(\"Computing the mean of 'Chromium Total' took {} seonds, and the mean is {}.\".format(mean_compute_time, ct_result_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79640cce",
   "metadata": {},
   "source": [
    "- The CSV file used in the test has the size of 5,322,234,734 bytes.\n",
    "\n",
    "First loop:\n",
    "- Without Apache Arrow, reading the file contents into a Pandas dataframe takes 169.74 seconds. With Apache Arrow, it  reads in the same file to a pyarrow table in 88.06 seconds, which is roughly 48.12% faster.\n",
    "- Without Apache Arrow, computing the mean Result of the Paramenter 'Chronium Total' takes 3.4 seconds. With Apache Arrow, it computes the mean in 2.15 seconds, which is ~36.76% faster. \n",
    "\n",
    "Second loop:\n",
    "- Without Apache Arrow, reading the file contents into a Pandas dataframe takes 210.94 seconds. With Apache Arrow, it  reads in the same file to a pyarrow table in 433.33 seconds, which is roughly 105.43% slower.\n",
    "- Without Apache Arrow, computing the mean Result of the Paramenter 'Chronium Total' takes 1.36 seconds. With Apache Arrow, it computes the mean in 2.19 seconds, which is ~61.03% slower. \n",
    "\n",
    "Third loop:\n",
    "- Without Apache Arrow, computing the mean Result of the Paramenter 'Chronium Total' takes 1.30 seconds. With Apache Arrow, it computes the mean in 2.18 seconds, which is ~67.69% slower. \n",
    "\n",
    "- The mean Result is 1.5669242911547947 mg/L.\n",
    "\n",
    "Observation:\n",
    "Apache Arrow improves performance of reading large CSV files as well as computing the mean value of Result, by 48.12% and 36.76% respectively, in the first loop. Interestingly, the CSV reading time increased in the second loop. However, the time increase using Apache Arrow is more significant than the one without. It is possible that PyArrow performance is affected more by the memory usage pattern. \n",
    "For compute time, the increase in the 2nd and 3rd loop is not as big. Also, because Apache Arrow does not support query table data at the moment we have to convert pyarrow table to pandas dataframe before doing the calculation. This increases the compute time.\n",
    "\n",
    "Note: \n",
    "1. I did not explore iterating pyarrow table rows and do the calculation that way (seems like looping through rows is not supported.)\n",
    "2. To better evaluate the performance, we should remove the loop around reading CSV files and compute and re-run the notebook multiple times instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
